// Smoldot
// Copyright (C) 2019-2022  Parity Technologies (UK) Ltd.
// SPDX-License-Identifier: GPL-3.0-or-later WITH Classpath-exception-2.0

// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.

// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.

// You should have received a copy of the GNU General Public License
// along with this program.  If not, see <http://www.gnu.org/licenses/>.

//! Background network service.
//!
//! The [`NetworkService`] manages background tasks dedicated to connecting to other nodes.
//! Importantly, its design is oriented towards the particular use case of the full node.
//!
//! The [`NetworkService`] spawns one background task (using the [`Config::tasks_executor`]) for
//! each active TCP socket, plus one for each TCP listening socket. Messages are exchanged between
//! the service and these background tasks.

// TODO: doc
// TODO: re-review this once finished

use crate::run::{database_thread, jaeger_service};

use core::{cmp, future::Future, mem, pin::Pin, task::Poll, time::Duration};
use futures_channel::oneshot;
use hashbrown::HashMap;
use smol::{
    channel, future,
    lock::Mutex,
    net::TcpStream,
    stream::{Stream, StreamExt as _},
};
use smoldot::{
    database::full_sqlite,
    header,
    informant::HashDisplay,
    libp2p::{
        connection,
        multiaddr::{Multiaddr, ProtocolRef},
        peer_id::{self, PeerId},
        peers,
    },
    network::{protocol, service},
};
use std::{
    io, iter,
    net::{IpAddr, SocketAddr},
    num::NonZeroUsize,
    sync::Arc,
    time::Instant,
};

mod tasks;

/// Configuration for a [`NetworkService`].
pub struct Config {
    /// Closure that spawns background tasks.
    pub tasks_executor: Box<dyn FnMut(Pin<Box<dyn Future<Output = ()> + Send>>) + Send>,

    /// Number of event receivers returned by [`NetworkService::new`].
    pub num_events_receivers: usize,

    /// Addresses to listen for incoming connections.
    pub listen_addresses: Vec<Multiaddr>,

    /// List of block chains to be connected to.
    pub chains: Vec<ChainConfig>,

    /// Value sent back for the agent version when receiving an identification request.
    pub identify_agent_version: String,

    /// Key used for the encryption layer.
    /// This is a Noise static key, according to the Noise specification.
    /// Signed using the actual libp2p key.
    pub noise_key: connection::NoiseKey,

    /// Service to use to report traces.
    pub jaeger_service: Arc<jaeger_service::JaegerService>,
}

/// Configuration for one chain.
pub struct ChainConfig {
    /// List of node identities and addresses that are known to belong to the chain's peer-to-pee
    /// network.
    pub bootstrap_nodes: Vec<(PeerId, Multiaddr)>,

    /// Database to use to read blocks from when answering requests.
    pub database: Arc<database_thread::DatabaseThread>,

    /// Hash of the genesis block of the chain. Sent to other nodes in order to determine whether
    /// the chains match.
    pub genesis_block_hash: [u8; 32],

    /// Number and hash of the current best block. Can later be updated with // TODO: which function?
    pub best_block: (u64, [u8; 32]),

    /// Optional identifier to insert into the networking protocol names. Used to differentiate
    /// between chains with the same genesis hash.
    pub fork_id: Option<String>,

    /// Number of bytes of the block number in the networking protocol.
    pub block_number_bytes: usize,

    /// If true, the chain uses the GrandPa networking protocol.
    pub has_grandpa_protocol: bool,
}

/// Event generated by the events reporters returned by [`NetworkService::new`].
#[derive(Debug, Clone)]
pub enum Event {
    Connected {
        chain_index: usize,
        peer_id: PeerId,
        best_block_number: u64,
        best_block_hash: [u8; 32],
    },
    Disconnected {
        chain_index: usize,
        peer_id: PeerId,
    },
    BlockAnnounce {
        chain_index: usize,
        peer_id: PeerId,
        header: header::Header,
        is_best: bool,
    },
}

pub struct NetworkService {
    /// Identity of the local node.
    local_peer_id: PeerId,

    /// Service to use to report traces.
    jaeger_service: Arc<jaeger_service::JaegerService>,

    /// Channel to send messages to the background task.
    to_background_tx: Mutex<channel::Sender<ToBackground>>,

    /// Notified when the service shuts down.
    foreground_shutdown: event_listener::Event,
}

enum ToBackground {
    FromConnectionTask {
        connection_id: service::ConnectionId,
        opaque_message: Option<service::ConnectionToCoordinator>,
        connection_now_dead: bool,
    },
    ConnectionEstablishSuccess {
        socket: Box<dyn tasks::AsyncReadWrite + Send + Unpin>,
        info: service::StartConnect<Instant>,
    },
    ConnectionEstablishFail {
        info: service::StartConnect<Instant>,
    },
    IncomingConnection {
        socket: TcpStream,
        multiaddr: Multiaddr,
        when_connected: Instant,
    },
    StartKademliaDiscoveries {
        when_done: oneshot::Sender<()>,
    },
    ForegroundAnnounceBlock {
        target: PeerId,
        chain_index: usize,
        scale_encoded_header: Vec<u8>,
        is_best: bool,
        result_tx: oneshot::Sender<Result<(), QueueNotificationError>>,
    },
    ForegroundSetLocalBestBlock {
        chain_index: usize,
        best_hash: [u8; 32],
        best_number: u64,
    },
    ForegroundBlocksRequest {
        target: PeerId,
        chain_index: usize,
        config: protocol::BlocksRequestConfig,
        result_tx: oneshot::Sender<Result<Vec<protocol::BlockData>, BlocksRequestError>>,
    },
    ForegroundGetNumEstablishedConnections {
        result_tx: oneshot::Sender<usize>,
    },
    ForegroundGetNumPeers {
        chain_index: usize,
        result_tx: oneshot::Sender<usize>,
    },
    ForegroundShutdown,
}
struct Inner {
    /// Value provided through [`Config::identify_agent_version`].
    identify_agent_version: String,

    /// Sending events through the public API.
    ///
    /// Contains either senders, or a `Future` that is currently sending an event and will yield
    /// the senders back once it is finished.
    event_senders: either::Either<
        Vec<channel::Sender<Event>>,
        Pin<Box<dyn Future<Output = Vec<channel::Sender<Event>>> + Send>>,
    >,

    /// Databases to use to read blocks from when answering requests.
    databases: Vec<Arc<database_thread::DatabaseThread>>,

    /// Identity of the local node.
    local_peer_id: PeerId,

    /// Service to use to report traces.
    jaeger_service: Arc<jaeger_service::JaegerService>,

    /// Data structure holding the entire state of the networking.
    network: service::ChainNetwork<Instant>,

    /// Current number of outgoing connection attempts.
    ///
    /// This counter is used to limit the number of simultaneous connection attempts, as some
    /// ISPs/cloud providers don't like seeing too many dialing connections at the same time.
    num_pending_out_attempts: usize,

    /// See [`Config::tasks_executor`].
    tasks_executor: Box<dyn FnMut(Pin<Box<dyn Future<Output = ()> + Send>>) + Send>,

    active_connections: HashMap<
        service::ConnectionId,
        channel::Sender<service::CoordinatorToConnection<Instant>>,
        fnv::FnvBuildHasher,
    >,

    /// List of peer and chain index tuples for which no outbound slot should be assigned.
    ///
    /// The values are the moment when the ban expires.
    // TODO: use SipHasher
    slots_assign_backoff: HashMap<(PeerId, usize), Instant, fnv::FnvBuildHasher>,

    process_network_service_events: bool,

    /// Channel for the various tasks to send messages to the background task.
    to_background_rx: channel::Receiver<ToBackground>,

    /// Sending side of [`Inner::to_background_rx`].
    to_background_tx: channel::Sender<ToBackground>,

    /// List of all block requests that have been started but not finished yet.
    blocks_requests: HashMap<
        service::OutRequestId,
        oneshot::Sender<Result<Vec<protocol::BlockData>, BlocksRequestError>>,
        fnv::FnvBuildHasher,
    >,

    /// List of Kademlia discovery operations that have been started but not finished yet.
    kademlia_discovery_operations:
        HashMap<service::KademliaOperationId, usize, fnv::FnvBuildHasher>,
}

impl NetworkService {
    /// Initializes the network service with the given configuration.
    pub async fn new(
        config: Config,
    ) -> Result<(Arc<Self>, Vec<Pin<Box<dyn Stream<Item = Event> + Send>>>), InitError> {
        let (event_senders, event_receivers): (Vec<_>, Vec<_>) = (0..config.num_events_receivers)
            .map(|_| channel::bounded(16))
            .unzip();

        let mut chains = Vec::with_capacity(config.chains.len());
        let mut databases = Vec::with_capacity(config.chains.len());
        for chain in &config.chains {
            chains.push(service::ChainConfig {
                in_slots: 25,
                out_slots: 25,
                fork_id: chain.fork_id.clone(),
                block_number_bytes: chain.block_number_bytes,
                best_hash: chain.best_block.1,
                best_number: chain.best_block.0,
                genesis_hash: chain.genesis_block_hash,
                role: protocol::Role::Full,
                grandpa_protocol_config: if chain.has_grandpa_protocol {
                    // TODO: dummy values
                    Some(service::GrandpaState {
                        commit_finalized_height: 0,
                        round_number: 1,
                        set_id: 0,
                    })
                } else {
                    None
                },
                allow_inbound_block_requests: true,
            });

            databases.push(chain.database.clone());
        }

        let mut network = service::ChainNetwork::new(service::Config {
            now: Instant::now(),
            chains,
            connections_capacity: 100, // TODO: ?
            peers_capacity: 100,       // TODO: ?
            noise_key: config.noise_key,
            handshake_timeout: Duration::from_secs(8),
            max_addresses_per_peer: NonZeroUsize::new(5).unwrap(),
            randomness_seed: rand::random(),
        });

        // Add the bootnodes to the inner state machine.
        for (chain_index, chain) in config.chains.into_iter().enumerate() {
            for (peer_id, addr) in chain.bootstrap_nodes {
                network.discover(&Instant::now(), chain_index, peer_id, iter::once(addr));
            }
        }

        let (to_background_tx, to_background_rx) = channel::bounded(64);
        let foreground_shutdown = event_listener::Event::new();

        let local_peer_id =
            peer_id::PublicKey::Ed25519(*network.noise_key().libp2p_public_ed25519_key())
                .into_peer_id();

        // Initialize the inner network service.
        let mut inner = Inner {
            local_peer_id: local_peer_id.clone(),
            identify_agent_version: config.identify_agent_version,
            event_senders: either::Left(event_senders),
            databases,
            num_pending_out_attempts: 0,
            to_background_rx,
            to_background_tx: to_background_tx.clone(),
            process_network_service_events: true,
            tasks_executor: config.tasks_executor,
            network,
            slots_assign_backoff: hashbrown::HashMap::with_capacity_and_hasher(
                50, // TODO: ?
                Default::default(),
            ),
            active_connections: hashbrown::HashMap::with_capacity_and_hasher(
                100, // TODO: ?
                Default::default(),
            ),
            blocks_requests: hashbrown::HashMap::with_capacity_and_hasher(
                50, // TODO: ?
                Default::default(),
            ),
            kademlia_discovery_operations: hashbrown::HashMap::with_capacity_and_hasher(
                4,
                Default::default(),
            ),
            jaeger_service: config.jaeger_service.clone(),
        };

        // For each listening address in the configuration, create a background task dedicated to
        // listening on that address.
        for listen_address in config.listen_addresses {
            // Try to parse the requested address and create the corresponding listening socket.
            let tcp_listener: smol::net::TcpListener = {
                let addr = {
                    let mut iter = listen_address.iter();
                    let proto1 = iter.next();
                    let proto2 = iter.next();
                    let proto3 = iter.next();
                    match (proto1, proto2, proto3) {
                        (Some(ProtocolRef::Ip4(ip)), Some(ProtocolRef::Tcp(port)), None) => {
                            Some(SocketAddr::from((ip, port)))
                        }
                        (Some(ProtocolRef::Ip6(ip)), Some(ProtocolRef::Tcp(port)), None) => {
                            Some(SocketAddr::from((ip, port)))
                        }
                        _ => None,
                    }
                };

                if let Some(addr) = addr {
                    match smol::net::TcpListener::bind(addr).await {
                        Ok(l) => l,
                        Err(err) => {
                            return Err(InitError::ListenerIo(listen_address, err));
                        }
                    }
                } else {
                    // TODO: support WebSocket server
                    return Err(InitError::BadListenMultiaddr(listen_address));
                }
            };

            // Spawn a background task dedicated to this listener.
            (inner.tasks_executor)(Box::pin({
                let to_background_tx = to_background_tx.clone();
                let mut on_foreground_shutdown = foreground_shutdown.listen();
                async move {
                    loop {
                        let Some(accept_result) =
                            future::or(async {
                                (&mut on_foreground_shutdown).await;
                                None
                            }, async { Some(tcp_listener.accept().await) })
                            .await
                            else { break };

                        let (socket, addr) = match accept_result {
                            Ok(v) => v,
                            Err(_) => {
                                // Errors here can happen if the accept failed, for example if no
                                // file descriptor is available.
                                // A wait is added in order to avoid having a busy-loop failing to
                                // accept connections.
                                smol::Timer::after(Duration::from_secs(2)).await;
                                continue;
                            }
                        };

                        // The Nagle algorithm, implemented in the kernel, consists in buffering the
                        // data to be sent out and waiting a bit before actually sending it out, in
                        // order to potentially merge multiple writes in a row into one packet. In
                        // the implementation below, it is guaranteed that the buffer in `WithBuffers`
                        // is filled with as much data as possible before the operating system gets
                        // involved. As such, we disable the Nagle algorithm, in order to avoid adding
                        // an artificial delay to all sends.
                        let _ = socket.set_nodelay(true);

                        let multiaddr = [
                            match addr.ip() {
                                IpAddr::V4(ip) => ProtocolRef::Ip4(ip.octets()),
                                IpAddr::V6(ip) => ProtocolRef::Ip6(ip.octets()),
                            },
                            ProtocolRef::Tcp(addr.port()),
                        ]
                        .into_iter()
                        .collect::<Multiaddr>();

                        log::debug!("incoming-connection; multiaddr={}", multiaddr);

                        let _ = to_background_tx
                            .send(ToBackground::IncomingConnection {
                                socket,
                                multiaddr,
                                when_connected: Instant::now(),
                            })
                            .await;
                    }
                }
            }))
        }

        // Spawn a task that sends a "shutdown" message whenever the service shuts down.
        (inner.tasks_executor)({
            let on_foreground_shutdown = foreground_shutdown.listen();
            let to_background_tx = to_background_tx.clone();
            Box::pin(async move {
                let _ = on_foreground_shutdown.await;
                let _ = to_background_tx
                    .send(ToBackground::ForegroundShutdown)
                    .await;
            })
        });

        // Spawn task starts a discovery request at a periodic interval.
        // This is done through a separate task due to ease of implementation.
        (inner.tasks_executor)(Box::pin({
            let to_background_tx = to_background_tx.clone();
            let mut on_foreground_shutdown = foreground_shutdown.listen();
            async move {
                let mut next_discovery = Duration::from_secs(1);

                loop {
                    let still_alive = future::race(
                        async {
                            smol::Timer::after(next_discovery).await;
                            true
                        },
                        async {
                            (&mut on_foreground_shutdown).await;
                            false
                        },
                    )
                    .await;
                    if !still_alive {
                        break;
                    }

                    next_discovery = cmp::min(next_discovery * 2, Duration::from_secs(120));
                    let (when_done, when_done_rx) = oneshot::channel();
                    let _ = to_background_tx
                        .send(ToBackground::StartKademliaDiscoveries { when_done })
                        .await;
                    let _ = when_done_rx.await;
                }
            }
        }));

        // Build the final network service.
        let network_service = Arc::new(NetworkService {
            local_peer_id,
            jaeger_service: config.jaeger_service,
            to_background_tx: Mutex::new(to_background_tx),
            foreground_shutdown,
        });

        // Spawn the main task dedicated to processing the network.
        run(inner);

        // Adjust the receivers to keep the `network_service` alive.
        // TODO: no, hacky
        let receivers = event_receivers
            .into_iter()
            .map(|rx| {
                let mut network_service = Some(network_service.clone());
                rx.chain(smol::stream::poll_fn(move |_| {
                    drop(network_service.take());
                    Poll::Ready(None)
                }))
                .boxed()
            })
            .collect();

        Ok((network_service, receivers))
    }

    /// Returns the number of established TCP connections, both incoming and outgoing.
    pub async fn num_established_connections(&self) -> usize {
        let (result_tx, result_rx) = oneshot::channel();

        let _ = self
            .to_background_tx
            .lock()
            .await
            .send(ToBackground::ForegroundGetNumEstablishedConnections { result_tx })
            .await;

        result_rx.await.unwrap()
    }

    /// Returns the number of peers we have a substream with.
    pub async fn num_peers(&self, chain_index: usize) -> usize {
        let (result_tx, result_rx) = oneshot::channel();

        let _ = self
            .to_background_tx
            .lock()
            .await
            .send(ToBackground::ForegroundGetNumPeers {
                chain_index,
                result_tx,
            })
            .await;

        result_rx.await.unwrap()
    }

    pub async fn set_local_best_block(
        &self,
        chain_index: usize,
        best_hash: [u8; 32],
        best_number: u64,
    ) {
        let _ = self
            .to_background_tx
            .lock()
            .await
            .send(ToBackground::ForegroundSetLocalBestBlock {
                chain_index,
                best_hash,
                best_number,
            })
            .await;
    }

    pub async fn send_block_announce(
        self: Arc<Self>,
        target: PeerId,
        chain_index: usize,
        scale_encoded_header: Vec<u8>,
        is_best: bool,
    ) -> Result<(), QueueNotificationError> {
        let (result_tx, result_rx) = oneshot::channel();

        let _ = self
            .to_background_tx
            .lock()
            .await
            .send(ToBackground::ForegroundAnnounceBlock {
                target,
                chain_index,
                scale_encoded_header,
                is_best,
                result_tx,
            })
            .await;

        result_rx.await.unwrap()
    }

    /// Sends a blocks request to the given peer.
    // TODO: more docs
    // TODO: proper error type
    pub async fn blocks_request(
        self: Arc<Self>,
        target: PeerId, // TODO: by value?
        chain_index: usize,
        config: protocol::BlocksRequestConfig,
    ) -> Result<Vec<protocol::BlockData>, BlocksRequestError> {
        log::debug!(
            "blocks-request-start; perr_id={}; chain_index={}; start={}; desired_count={}; direction={}",
            target, chain_index,
            match &config.start {
                protocol::BlocksRequestConfigStart::Hash(h) => either::Left(HashDisplay(h)),
                protocol::BlocksRequestConfigStart::Number(n) => either::Right(n),
            },
            config.desired_count,
            match config.direction {
                protocol::BlocksRequestDirection::Ascending => "ascending",
                protocol::BlocksRequestDirection::Descending => "descending",
            },
        );

        // Setup a guard that will print a log message in case it is dropped silently.
        // This lets us detect if the request is cancelled.
        struct LogIfCancel(PeerId, usize);
        impl Drop for LogIfCancel {
            fn drop(&mut self) {
                log::debug!(
                    "blocks-request-ended; peer_id={}; chain_index={}; outcome=cancelled",
                    self.0,
                    self.1
                );
            }
        }
        let _log_if_cancel = LogIfCancel(target.clone(), chain_index);

        let _jaeger_span = self.jaeger_service.outgoing_block_request_span(
            &self.local_peer_id,
            &target,
            config.desired_count.get(),
            if let (1, protocol::BlocksRequestConfigStart::Hash(block_hash)) =
                (config.desired_count.get(), &config.start)
            {
                Some(block_hash)
            } else {
                None
            },
        );

        let (result_tx, result_rx) = oneshot::channel();

        let _ = self
            .to_background_tx
            .lock()
            .await
            .send(ToBackground::ForegroundBlocksRequest {
                target: target.clone(),
                chain_index,
                config,
                result_tx,
            })
            .await;

        let result = result_rx.await.unwrap();

        // Requet has finished. Print the log and prevent the cancellation message from being
        // printed.
        mem::forget(_log_if_cancel);
        match &result {
            Ok(success) => {
                log::debug!(
                    "blocks-request-ended; peer_id={}; chain_index={}; outcome=success; response_blocks={}",
                    target, chain_index, success.len()
                );
            }
            Err(err) => {
                log::debug!(
                    "blocks-request-ended; peer_id={}; chain_index={}; outcome=failure; error={}",
                    target,
                    chain_index,
                    err
                );
            }
        }

        result
    }
}

impl Drop for NetworkService {
    fn drop(&mut self) {
        self.foreground_shutdown.notify(usize::max_value());
    }
}

/// Error when initializing the network service.
#[derive(Debug, derive_more::Display)]
pub enum InitError {
    /// I/O error when initializing a listener.
    #[display(fmt = "I/O error when creating listener for {_0}: {_1}")]
    ListenerIo(Multiaddr, io::Error),
    /// A listening address passed through the configuration isn't valid.
    #[display(fmt = "A listening address passed through the configuration isn't valid: {_0}")]
    BadListenMultiaddr(Multiaddr),
}

/// Error returned by [`NetworkService::blocks_request`].
#[derive(Debug, derive_more::Display)]
pub enum BlocksRequestError {
    /// No established connection with the target.
    NoConnection,
    /// Error during the request.
    #[display(fmt = "{_0}")]
    Request(service::BlocksRequestError),
}

/// Error returned by [`NetworkService::send_block_announce`].
#[derive(Debug, derive_more::Display)]
pub enum QueueNotificationError {
    /// No established connection with the target.
    NoConnection,
    /// Error during the queuing.
    #[display(fmt = "{_0}")]
    Queue(peers::QueueNotificationError),
}

fn run(mut inner: Inner) {
    // This function is a small hack because I didn't find a better way to store the executor
    // within `Inner` while at the same time spawning the `Inner` using said executor.
    let mut actual_executor = mem::replace(&mut inner.tasks_executor, Box::new(|_| unreachable!()));
    let (tx, rx) = oneshot::channel();
    actual_executor(Box::pin(async move {
        let actual_executor = rx.await.unwrap();
        inner.tasks_executor = actual_executor;
        background_task(inner).await;
    }));
    tx.send(actual_executor).unwrap_or_else(|_| panic!());
}

async fn background_task(mut inner: Inner) {
    loop {
        // Pull messages that the coordinator has generated in destination to the various
        // connections.
        while let Some((connection_id, message)) = inner.network.pull_message_to_connection() {
            // Note that it is critical for the sending to not take too long here, in order to not
            // block the process of the network service.
            // In particular, if sending the message to the connection is blocked due to sending
            // a message on the connection-to-coordinator channel, this will result in a deadlock.
            // For this reason, the connection task is always ready to immediately accept a message
            // on the coordinator-to-connection channel.
            inner
                .active_connections
                .get_mut(&connection_id)
                .unwrap()
                .send(message)
                .await
                .unwrap();
        }

        if inner.process_network_service_events && matches!(inner.event_senders, either::Left(_)) {
            let event = loop {
                let inner_event = match inner.network.next_event(Instant::now()) {
                    Some(ev) => ev,
                    None => break None,
                };

                match inner_event {
                    service::Event::Connected(peer_id) => {
                        log::debug!("connected; peer_id={}", peer_id);
                    }
                    service::Event::Disconnected {
                        peer_id,
                        chain_indices,
                    } => {
                        log::debug!("disconnected; peer_id={}", peer_id);
                        if !chain_indices.is_empty() {
                            debug_assert_eq!(chain_indices.len(), 1); // TODO: not implemented
                            break Some(Event::Disconnected {
                                chain_index: chain_indices[0],
                                peer_id,
                            });
                        }
                    }
                    service::Event::BlockAnnounce {
                        chain_index,
                        peer_id,
                        announce,
                    } => {
                        let decoded = announce.decode();
                        let header_hash =
                            header::hash_from_scale_encoded_header(decoded.scale_encoded_header);
                        match header::decode(
                            decoded.scale_encoded_header,
                            inner.network.block_number_bytes(chain_index),
                        ) {
                            Ok(decoded_header) => {
                                let mut _jaeger_span =
                                    inner.jaeger_service.block_announce_receive_span(
                                        &inner.local_peer_id,
                                        &peer_id,
                                        decoded_header.number,
                                        &decoded_header
                                            .hash(inner.network.block_number_bytes(chain_index)),
                                    );

                                log::debug!(
                                    "block-announce; peer_id={}; chain_index={}; hash={}; number={}; is_best={:?}",
                                    peer_id, chain_index, HashDisplay(&header_hash), decoded_header.number, decoded.is_best
                                );

                                break Some(Event::BlockAnnounce {
                                    chain_index,
                                    peer_id,
                                    is_best: decoded.is_best,
                                    header: decoded_header.into(), // TODO: somewhat wasteful allocation here
                                });
                            }
                            Err(error) => {
                                log::warn!(
                                    "block-announce-bad-header; peer_id={}; chain_index={}; hash={}; is_best={:?}; error={}",
                                    peer_id, chain_index, HashDisplay(&header_hash), decoded.is_best, error
                                );

                                inner.unassign_slot_and_ban(chain_index, peer_id);
                                inner.process_network_service_events = true;
                            }
                        }
                    }
                    service::Event::ChainConnected {
                        peer_id,
                        chain_index,
                        best_number,
                        best_hash,
                        ..
                    } => {
                        log::debug!(
                            "chain-connected; peer_id={}; chain_index={}; best_number={}; best_hash={}",
                            peer_id,
                            chain_index,
                            best_number,
                            HashDisplay(&best_hash),
                        );
                        break Some(Event::Connected {
                            peer_id,
                            chain_index,
                            best_block_number: best_number,
                            best_block_hash: best_hash,
                        });
                    }
                    service::Event::ChainDisconnected {
                        peer_id,
                        chain_index,
                        ..
                    } => {
                        log::debug!(
                            "chain-disconnected; peer_id={}; chain_index={}",
                            peer_id,
                            chain_index
                        );

                        inner.unassign_slot_and_ban(chain_index, peer_id.clone());
                        inner.process_network_service_events = true;

                        break Some(Event::Disconnected {
                            chain_index,
                            peer_id,
                        });
                    }
                    service::Event::ChainConnectAttemptFailed {
                        chain_index,
                        peer_id,
                        error,
                        ..
                    } => {
                        log::debug!(
                            "chain-connect-attempt-failed; peer_id={}; chain_index={}; error={}",
                            peer_id,
                            chain_index,
                            error
                        );

                        inner.unassign_slot_and_ban(chain_index, peer_id);
                        inner.process_network_service_events = true;
                    }
                    service::Event::InboundSlotAssigned { .. } => {
                        // TODO: log this
                    }
                    service::Event::RequestResult {
                        request_id,
                        response: service::RequestResult::Blocks(response),
                    } => {
                        let _ = inner
                            .blocks_requests
                            .remove(&request_id)
                            .unwrap()
                            .send(response.map_err(BlocksRequestError::Request));
                    }
                    service::Event::RequestResult { .. } => {
                        // We never start a request of any other kind.
                        unreachable!()
                    }
                    service::Event::RequestInCancel { .. } => {
                        // Requests are answered immediately, and thus cancelling events can't happen.
                        unreachable!()
                    }
                    service::Event::KademliaDiscoveryResult {
                        operation_id,
                        result,
                    } => {
                        let chain_index = inner
                            .kademlia_discovery_operations
                            .remove(&operation_id)
                            .unwrap();
                        match result {
                            Ok(nodes) => {
                                log::debug!("discovered; nodes={:?}", nodes);
                                for (peer_id, addrs) in nodes {
                                    inner.network.discover(
                                        &Instant::now(),
                                        chain_index,
                                        peer_id,
                                        addrs,
                                    );
                                }
                            }
                            Err(error) => {
                                log::debug!("discovery-error; error={}", error);
                            }
                        }
                    }
                    service::Event::IdentifyRequestIn {
                        peer_id,
                        request_id,
                    } => {
                        log::debug!("identify-request; peer_id={}", peer_id);
                        inner
                            .network
                            .respond_identify(request_id, &inner.identify_agent_version);
                    }
                    service::Event::BlocksRequestIn {
                        peer_id,
                        chain_index,
                        config,
                        request_id,
                    } => {
                        log::debug!(
                            "incoming-blocks-request; peer_id={}; chain_index={}",
                            peer_id,
                            chain_index
                        );
                        let mut _jaeger_span = inner.jaeger_service.incoming_block_request_span(
                            &inner.local_peer_id,
                            &peer_id,
                            config.desired_count.get(),
                            if let (1, protocol::BlocksRequestConfigStart::Hash(block_hash)) =
                                (config.desired_count.get(), &config.start)
                            {
                                Some(block_hash)
                            } else {
                                None
                            },
                        );

                        // TODO: is it a good idea to await here while the lock is held and freezing the entire networking background task?
                        let response = blocks_request_response(
                            &inner.databases[chain_index],
                            inner.network.block_number_bytes(chain_index),
                            config,
                        )
                        .await;
                        inner.network.respond_blocks(
                            request_id,
                            match response {
                                Ok(b) => Some(b),
                                Err(error) => {
                                    log::warn!("incoming-blocks-request-error; error={}", error);
                                    None
                                }
                            },
                        );
                    }
                    service::Event::GrandpaNeighborPacket {
                        chain_index,
                        peer_id,
                        state,
                    } => {
                        log::debug!(
                            "grandpa-neighbor-packet; peer_id={}; chain_index={}; round_number={}; set_id={}; commit_finalized_height={}",
                            peer_id,
                            chain_index,
                            state.round_number,
                            state.set_id,
                            state.commit_finalized_height,
                        );
                        // TODO: report to the sync state machine
                    }
                    service::Event::GrandpaCommitMessage {
                        chain_index,
                        peer_id,
                        message,
                    } => {
                        log::debug!(
                            "grandpa-commit-message; peer_id={}; chain_index={}; target_hash={}",
                            peer_id,
                            chain_index,
                            HashDisplay(message.decode().message.target_hash),
                        );
                    }
                    service::Event::ProtocolError { peer_id, error } => {
                        log::warn!("protocol-error; peer_id={}; error={}", peer_id, error);
                        for chain_index in 0..inner.network.num_chains() {
                            inner.unassign_slot_and_ban(chain_index, peer_id.clone());
                        }
                        inner.process_network_service_events = true;
                    }
                }
            };

            // Dispatch the event to the various senders.
            if let Some(event) = event {
                // Continue processing events.
                inner.process_network_service_events = true;

                // We check this before generating an event.
                let either::Left(mut event_senders) = inner.event_senders
                    else { unreachable!() };

                inner.event_senders = either::Right(Box::pin(async move {
                    // This little `if` avoids having to do `event.clone()` if we don't have to.
                    if event_senders.len() == 1 {
                        let _ = event_senders[0].send(event).await;
                    } else {
                        for sender in event_senders.iter_mut() {
                            // For simplicity we don't get rid of closed senders because senders
                            // aren't supposed to close, and that leaving closed senders in the
                            // list doesn't have any consequence other than one extra iteration
                            // every time.
                            let _ = sender.send(event.clone()).await;
                        }
                    }

                    event_senders
                }));
            }

            // TODO: doc
            for chain_index in 0..inner.network.num_chains() {
                let now = Instant::now();

                // Clean up the content of `slots_assign_backoff`.
                // TODO: the background task should be woken up when the ban expires
                // TODO: O(n)
                inner
                    .slots_assign_backoff
                    .retain(|_, expiration| *expiration > now);

                // Assign outgoing slots.
                loop {
                    let peer_to_assign = inner
                        .network
                        .slots_to_assign(chain_index)
                        .find(|peer_id| {
                            !inner
                                .slots_assign_backoff
                                .contains_key(&((**peer_id).clone(), chain_index))
                            // TODO: spurious cloning
                        })
                        .cloned();

                    let Some(peer_to_assign) = peer_to_assign else { break };
                    log::debug!(
                        "slot-assigned; peer_id={}; chain_index={}",
                        peer_to_assign,
                        chain_index
                    );
                    inner.network.assign_out_slot(chain_index, peer_to_assign);
                    inner.process_network_service_events = true;
                }
            }

            // The networking service contains a list of connections that should be opened.
            // Grab this list and start opening a connection for each.
            // TODO: restore the rate limiting for connections openings
            loop {
                if inner.num_pending_out_attempts >= 16 {
                    // TODO: constant
                    break;
                }

                let start_connect = match inner.network.next_start_connect(Instant::now) {
                    Some(sc) => sc,
                    None => break,
                };

                inner.num_pending_out_attempts += 1;

                // Perform the connection process in a separate task.
                let to_background_tx = inner.to_background_tx.clone();
                (inner.tasks_executor)(Box::pin(async move {
                    // TODO: interrupt immediately if `to_background_tx` is dropped
                    if let Ok(socket) = tasks::opening_connection_task(start_connect.clone()).await
                    {
                        let _ = to_background_tx
                            .send(ToBackground::ConnectionEstablishSuccess {
                                socket: Box::new(socket),
                                info: start_connect,
                            })
                            .await;
                    } else {
                        let _ = to_background_tx
                            .send(ToBackground::ConnectionEstablishFail {
                                info: start_connect,
                            })
                            .await;
                    }
                }));

                inner.process_network_service_events = true;
            }
        }

        let message = match inner.event_senders {
            either::Left(_) => inner.to_background_rx.next().await.unwrap(),
            either::Right(sending) => {
                match futures_util::future::select(inner.to_background_rx.next(), sending).await {
                    futures_util::future::Either::Left((message, sending)) => {
                        inner.event_senders = either::Right(sending);
                        message.unwrap()
                    }
                    futures_util::future::Either::Right((event_senders, _)) => {
                        inner.event_senders = either::Left(event_senders);
                        continue;
                    }
                }
            }
        };

        // TODO: this code block is obviously way too long; split into a struct
        match message {
            ToBackground::FromConnectionTask {
                connection_id,
                opaque_message,
                connection_now_dead,
            } => {
                if let Some(opaque_message) = opaque_message {
                    inner
                        .network
                        .inject_connection_message(connection_id, opaque_message);
                }

                // TODO: it should be indicated by the coordinator when a connection dies
                if connection_now_dead {
                    let _was_in = inner.active_connections.remove(&connection_id);
                    debug_assert!(_was_in.is_some());
                }

                inner.process_network_service_events = true;
            }

            ToBackground::ConnectionEstablishFail { info } => {
                inner.num_pending_out_attempts -= 1;
                inner.network.pending_outcome_err(info.id, true);
                for chain_index in 0..inner.network.num_chains() {
                    inner.unassign_slot_and_ban(chain_index, info.expected_peer_id.clone());
                }
                inner.process_network_service_events = true;
            }

            ToBackground::ConnectionEstablishSuccess { socket, info } => {
                inner.num_pending_out_attempts -= 1;

                let (connection_id, connection_task) =
                    inner.network.pending_outcome_ok_single_stream(
                        info.id,
                        service::SingleStreamHandshakeKind::MultistreamSelectNoiseYamux,
                    );

                let (tx, rx) = channel::bounded(16); // TODO: ?!
                inner.active_connections.insert(connection_id, tx);

                (inner.tasks_executor)(Box::pin(tasks::established_connection_task(
                    socket,
                    connection_id,
                    connection_task,
                    rx,
                    inner.to_background_tx.clone(),
                )));

                inner.process_network_service_events = true;
            }

            ToBackground::IncomingConnection {
                socket,
                multiaddr,
                when_connected,
            } => {
                let (connection_id, connection_task) =
                    inner.network.add_single_stream_incoming_connection(
                        when_connected,
                        service::SingleStreamHandshakeKind::MultistreamSelectNoiseYamux,
                        multiaddr,
                    );

                let (tx, rx) = channel::bounded(16); // TODO: ?!
                inner.active_connections.insert(connection_id, tx);

                (inner.tasks_executor)(Box::pin(tasks::established_connection_task(
                    socket,
                    connection_id,
                    connection_task,
                    rx,
                    inner.to_background_tx.clone(),
                )));

                inner.process_network_service_events = true;
            }

            ToBackground::StartKademliaDiscoveries { when_done } => {
                for chain_index in 0..inner.databases.len() {
                    let operation_id = inner
                        .network
                        .start_kademlia_discovery_round(Instant::now(), chain_index);
                    let _prev_val = inner
                        .kademlia_discovery_operations
                        .insert(operation_id, chain_index);
                    debug_assert!(_prev_val.is_none());
                }

                let _ = when_done.send(());

                inner.process_network_service_events = true;
            }

            ToBackground::ForegroundShutdown => {
                // TODO: do a clean shutdown of all the connections
                return;
            }

            ToBackground::ForegroundAnnounceBlock {
                target,
                chain_index,
                scale_encoded_header,
                is_best,
                result_tx,
            } => {
                // The call to `send_block_announce` below panics if we have no active connection.
                let result = if inner.network.can_send_block_announces(&target, chain_index) {
                    inner
                        .network
                        .send_block_announce(&target, chain_index, &scale_encoded_header, is_best)
                        .map_err(QueueNotificationError::Queue)
                } else {
                    Err(QueueNotificationError::NoConnection)
                };

                let _ = result_tx.send(result);
            }
            ToBackground::ForegroundSetLocalBestBlock {
                chain_index,
                best_hash,
                best_number,
            } => {
                inner
                    .network
                    .set_local_best_block(chain_index, best_hash, best_number);
            }
            ToBackground::ForegroundBlocksRequest {
                target,
                chain_index,
                config,
                result_tx,
            } => {
                // The call to `start_blocks_request` below panics if we have no active connection.
                if inner.network.can_start_requests(&target) {
                    let request_id = inner.network.start_blocks_request(
                        Instant::now(),
                        &target,
                        chain_index,
                        config,
                        Duration::from_secs(12),
                    );

                    // TODO: somehow cancel the request if the `rx` is dropped?
                    inner.blocks_requests.insert(request_id, result_tx);
                } else {
                    let _ = result_tx.send(Err(BlocksRequestError::NoConnection));
                }
            }
            ToBackground::ForegroundGetNumEstablishedConnections { result_tx } => {
                let _ = result_tx.send(inner.network.num_established_connections());
            }
            ToBackground::ForegroundGetNumPeers {
                chain_index,
                result_tx,
            } => {
                let _ = result_tx.send(inner.network.num_peers(chain_index));
            }
        }
    }
}

impl Inner {
    fn unassign_slot_and_ban(&mut self, chain_index: usize, peer_id: PeerId) {
        self.network.unassign_slot(chain_index, &peer_id);

        let new_expiration = Instant::now() + Duration::from_secs(20); // TODO: arbitrary constant
        match self.slots_assign_backoff.entry((peer_id, chain_index)) {
            hashbrown::hash_map::Entry::Occupied(e) if *e.get() < new_expiration => {
                *e.into_mut() = new_expiration;
            }
            hashbrown::hash_map::Entry::Occupied(_) => {}
            hashbrown::hash_map::Entry::Vacant(e) => {
                e.insert(new_expiration);
            }
        }
    }
}

/// Builds the response to a block request by reading from the given database.
async fn blocks_request_response(
    database: &database_thread::DatabaseThread,
    block_number_bytes: usize,
    config: protocol::BlocksRequestConfig,
) -> Result<Vec<protocol::BlockData>, full_sqlite::AccessError> {
    database
        .with_database(move |database| {
            let num_blocks = cmp::min(
                usize::try_from(config.desired_count.get()).unwrap_or(usize::max_value()),
                128,
            );

            let mut output = Vec::with_capacity(num_blocks);
            let mut next_block = config.start;

            loop {
                if output.len() >= num_blocks {
                    break;
                }

                let hash = match next_block {
                    protocol::BlocksRequestConfigStart::Hash(hash) => hash,
                    protocol::BlocksRequestConfigStart::Number(number) => {
                        // TODO: naive block selection ; should choose the best chain instead
                        match database.block_hash_by_number(number)?.next() {
                            Some(h) => h,
                            None => break,
                        }
                    }
                };

                let header = match database.block_scale_encoded_header(&hash)? {
                    Some(h) => h,
                    None => break,
                };

                next_block = {
                    let decoded = header::decode(&header, block_number_bytes).unwrap();
                    match config.direction {
                        protocol::BlocksRequestDirection::Ascending => {
                            // TODO: right now, since we don't necessarily pick the best chain in `block_hash_by_number`, it is possible that the next block doesn't have the current block as parent
                            protocol::BlocksRequestConfigStart::Number(decoded.number + 1)
                        }
                        protocol::BlocksRequestDirection::Descending => {
                            protocol::BlocksRequestConfigStart::Hash(*decoded.parent_hash)
                        }
                    }
                };

                output.push(protocol::BlockData {
                    hash,
                    header: if config.fields.header {
                        Some(header)
                    } else {
                        None
                    },
                    body: if config.fields.body {
                        Some(match database.block_extrinsics(&hash)? {
                            Some(body) => body.collect(),
                            None => break,
                        })
                    } else {
                        None
                    },
                    justifications: if config.fields.justifications {
                        // TODO: justifications aren't saved in database at the moment
                        Some(Vec::new())
                    } else {
                        None
                    },
                });
            }

            Ok(output)
        })
        .await
}
